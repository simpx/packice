# PackIce v1 Implementation Plan

## Objective
Wrap the PackIce node behind a transport-agnostic interface so multiple control/data path implementations can coexist. Preserve v0 semantics while adding a zero-IO, memory-focused variant that speaks over Unix Domain Sockets (UDS) and uses `memfd` attachments for data transfer.

## Goals
- Introduce a small node host layer that binds the core lease engine to pluggable control+data path adapters.
- Keep the only hard APIs (`Acquire`, `Seal`, `Release`) unchanged at the semantic level.
- Support two adapters at launch:
  - **HTTP + filesystem attachments** (existing v0 default)
  - **UDS + memfd attachments** (in-memory, copy-by-fd)
- Allow runtime selection (CLI flag / env) of adapter without recompiling.
- Maintain identical lease invariants, TTL handling, and object state transitions across adapters.

## Non-goals
- Changing wire schemas beyond transport framing (JSON payload stays the same).
- Distributed consensus, resolver changes, or new API verbs.
- Cross-adapter bridging in a single process (each process chooses one adapter).

## Architecture Overview
- **Core Engine** (shared): implements leases, attachments, resolver hints, eviction policy.
- **Control Path Adapter**: translates transport requests into core calls and serializes responses.
- **Data Path Adapter**: exposes the attachment handle appropriate to the transport (filesystem path or passed file descriptor).
- **Node Host**: wires adapters to the engine and configures logging/metrics; exports health/profiling endpoints if desired.

### Adapter Contracts
- **Control Path**
  - Must expose the three APIs with the same JSON schemas as v0.
  - Responsible for request auth/validation and mapping transport errors to API errors.
  - Must propagate TTL and lease IDs without modification.
- **Data Path**
  - Must surface read/write handles bound to lease lifetime.
  - Writable only while the lease is active and unsealed; read-only after `Seal`.
  - Enforces cleanup on `Release` or TTL expiry.

## Adapter Variants
### 1) HTTP + Filesystem (v0-compatible)
- Transport: HTTP/1.1 JSON on `0.0.0.0:$PORT`.
- Data attachment: filesystem path under `$PACKICE_DATA/attachments` created per lease.
- Response shape: attachment path string (as in v0).
- Operational focus: easy curl/debugging, simple file copying, durable across parent process restarts if directory persists.

### 2) UDS + memfd (new in-memory mode)
- Transport: Unix Domain Socket at `$PACKICE_SOCKET` (default `/tmp/packice.sock`), JSON framing over stream.
- Data attachment: `memfd_create` per lease; attachment handle passed back via FD passing on the UDS control socket.
- Response shape: JSON body mirrors v0 fields, with an `attachment_fd` number delivered via ancillary data; no filesystem path.
- Operational focus: zero disk I/O, safe in containers with read-only filesystems, faster local copies.
- Lease enforcement: memfd stays writable/readable only while lease active; closed on `Release`/TTL.

## Runtime Selection
- CLI: `packice-node --adapter=http` (default) or `packice-node --adapter=uds-memfd`.
- Environment alternative: `PACKICE_ADAPTER=http|uds-memfd` with CLI taking precedence.
- Configuration may also set `PACKICE_PORT`, `PACKICE_DATA`, or `PACKICE_SOCKET` depending on adapter.

## Compatibility & Interop
- API semantics identical: clients can reuse v0 request bodies; response differs only in attachment handle type.
- Resolver integration unchanged and shared in the core engine.
- Nodes of different adapters can still participate in copy-by-composition; copying bytes from a memfd-backed lease to a filesystem-backed lease uses the same acquire/copy/seal loop.

## Migration Steps
1. Extract core lease/data models from HTTP server into a shared library module.
2. Implement an adapter interface (`ControlAdapter`, `DataHandle`) with lifecycle hooks for `Acquire`, `Seal`, `Release`.
3. Refactor the existing HTTP server to sit behind the adapter interface (filesystem attachment provider).
4. Add UDS server with FD-passing helpers and memfd-backed attachment provider.
5. Extend tests/manual flows to cover both adapters (curl for HTTP; `socat`/custom client for UDS + FD passing).
6. Update packaging/CLI help and examples to advertise adapter selection.

## Example Flows
### HTTP (unchanged)
- Create: POST `/acquire` → write file → POST `/seal` → POST `/release`.
- Read miss: POST `/acquire` (read) → resolver hints → copy via attachments → seal and release.

### UDS + memfd
- Create: `echo '{"objid":"o1","intent":"create"}' | socat - UNIX-CONNECT:/tmp/packice.sock` → receive lease JSON + memfd; write bytes to FD → send `seal` and `release` commands over UDS.
- Read: request `acquire(read)` over UDS → receive memfd attachment FD → read bytes directly from memfd.

## Testing Strategy (v1)
- Unit tests for adapter boundary: lease lifecycle with both filesystem and memfd attachments.
- Integration smoke tests:
  - HTTP adapter: reuse v0 manual flows.
  - UDS adapter: script using `socat` or a small Go/Python client to issue JSON requests and exercise FD passing.
  - Cross-adapter copy: HTTP-backed node as source, UDS-backed node as destination (and vice versa) via composition flow.
- Benchmark sanity: measure create/seal/read latency for both adapters to validate memfd path improvements.
